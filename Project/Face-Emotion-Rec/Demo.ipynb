{"cells":[{"cell_type":"code","execution_count":null,"id":"09ad4a45","metadata":{"id":"09ad4a45"},"outputs":[],"source":["import cv2 as cv\n","# per gestire lo scatto della foto dal video\n","from cv2 import VideoCapture\n","# per caricare il modello CNN\n","from tensorflow import keras\n","# per pulire output console\n","from IPython.display import clear_output\n","# per operazioni con array\n","import numpy as np\n","import os # per gestire i path\n","import pickle\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"id":"072d0f79","metadata":{"id":"072d0f79"},"outputs":[],"source":["def start_demo(face_detector, model, dict_names):\n","    \"\"\"\n","    Visualizza una finestra con la riproduzione streaming catturata dalla camera principale\n","    del pc. Ad ogni frame viene quindi applicato il face detector e, se presente un volto,\n","    quest'ultimo viene passato al modello per riconoscere la persona.\n","    \n","    :param cv2.CascadeClassifier face_detector: Detector per il riconoscimento del volto\n","    :param keras.engine.functional.Functional model: Modello keras per la predizione\n","    :param str{} dict_names: Dizionario che associa nomi e numeri\n","    \"\"\"\n","        \n","    # nel caso ci siano errori chiudo la finestra in automatico\n","    try:\n","        # initialize the camera\n","        cam = VideoCapture(0)\n","\n","        while True:\n","            # acquisisco l'immagine dalla cam\n","            s, frame = cam.read()\n","            \n","            # se l'acquisizione non è andata a buon fine interrompo\n","            if not s:\n","                break\n","            else:\n","                # converto l'immagine in b/n\n","                img_bw = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n","                \n","                # applico il face detector sull'immagine in b/n\n","                faces = face_detector.detectMultiScale(img_bw, 1.1, 8)\n","\n","                for (x,y,w,h) in faces:\n","                    # visualizzo il rettangolo di detection\n","                    cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n","                    \n","                    # estraggo il crop\n","                    crop = frame[y:y+h, x:x+w]\n","                    # converto il crop a colori RGB\n","                    crop = cv.cvtColor(crop, cv.COLOR_BGR2RGB)\n","                    # riscalo il crop in 224x224\n","                    crop = cv.resize(crop, (224, 224)) \n","                    # aggiungo una dimensione\n","                    crop = np.expand_dims(crop, axis = 0)\n","                     \n","                    # applico il modello al crop\n","                    y_pred = model.predict(crop)\n","                    \n","                    # estraggo la predizione migliore\n","                    y_pred_max = np.argmax(y_pred)\n","                    \n","                    # ottengo la probabilità della previsione\n","                    y_pred = y_pred[0][y_pred_max]\n","                    \n","                    # se il modello predice con probabilità inferiore allora è incerto e quindi non visualizzo il testo\n","                    if y_pred > 0.0:\n","                        # visualizzo la previsione\n","                        cv.putText(frame, \n","                               (\"Person: \" + str(dict_names[y_pred_max])) + ' - ' + str(np.round(y_pred,3)), \n","                               ((x, y-5)), \n","                                cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n","                    \n","            \n","            # visualizzo la finestra\n","            cv.imshow('FaceRecognition', frame)\n","\n","            # Termino il ciclo se viene premuto Q\n","            if cv.waitKey(20) & 0xFF == ord('q'):\n","                break\n","        \n","        # rilascio la cam e chiudo la finestra se il ciclo è finito\n","        cam.release()\n","        cv.destroyAllWindows()\n","        \n","    except: # rilascio la cam e chiudo la finestra\n","        cam.release()\n","        cv.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"73a420f5","metadata":{"id":"73a420f5"},"outputs":[],"source":["# carico il modello di face detection pre-addestrato\n","face_detector = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","# carico il modello pre-trainato\n","loaded_model = keras.models.load_model('FaceRecBest.h5')"]},{"cell_type":"code","execution_count":null,"id":"78ee5602","metadata":{"id":"78ee5602"},"outputs":[],"source":["# definisco un dizionario con l'associazione Label-Nome\n","dict_name = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n","start_demo(face_detector, loaded_model, dict_name)"]},{"cell_type":"code","execution_count":null,"id":"-G-iSZU_ZI7E","metadata":{"id":"-G-iSZU_ZI7E"},"outputs":[],"source":["# per uscire dalla face-rec premere Q"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Demo.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}